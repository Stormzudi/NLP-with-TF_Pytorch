{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IE6b4n3ll_H"
   },
   "source": [
    "# 背景\n",
    "给定一个长句子预测下一个单词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eUATgBllr-_"
   },
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TTtyb4RjlgGp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tALLK06lxZv"
   },
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PrzpyXQilwr8"
   },
   "outputs": [],
   "source": [
    "sentence = (\n",
    "    'GitHub Actions makes it easy to automate all your software workflows '\n",
    "    'from continuous integration and delivery to issue triage and more'\n",
    ")\n",
    "# 其实就是个字符串，就是将上下两行字符串连接在一起的一个大字符串\n",
    "\n",
    "word2idx = {w: i for i, w in enumerate(list(set(sentence.split())))}\n",
    "idx2word = {i: w for i, w in enumerate(list(set(sentence.split())))}\n",
    "n_class = len(word2idx) # classification problem\n",
    "max_len = len(sentence.split())\n",
    "n_hidden = 5\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6C8XTPPbmGeG"
   },
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yfwAL23_mIqS"
   },
   "outputs": [],
   "source": [
    "def make_data(sentence):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    words = sentence.split()\n",
    "    for i in range(max_len - 1):\n",
    "        input = [word2idx[n] for n in words[:(i + 1)]]\n",
    "        input = input + [0] * (max_len - len(input)) # 用0填充，保证一样长\n",
    "        target = word2idx[words[i + 1]]\n",
    "        input_batch.append(np.eye(n_class)[input])\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return torch.Tensor(input_batch), torch.LongTensor(target_batch)\n",
    "\n",
    "# input_batch: [max_len - 1, max_len, n_class]\n",
    "input_batch, target_batch = make_data(sentence)\n",
    "dataset = Data.TensorDataset(input_batch, target_batch)\n",
    "loader = Data.DataLoader(dataset, batch_size, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R51sfRVjoJOK"
   },
   "source": [
    "# 定义网络架构\n",
    "## 构造\n",
    "- input_size – 输入数据的大小，也就是前面例子中每个单词向量的长度\n",
    "- hidden_size – 隐藏层的大小（即隐藏层节点数量），输出向量的维度等于隐藏节点数\n",
    "- num_layers – recurrent layer的数量，默认等于1。\n",
    "- bias – 网络是否设置偏置，默认是True.\n",
    "- batch_first – 默认为False，也就是说官方不推荐我们把batch放在第一维，这个CNN有点不同，此时输入输出的各个维度含义为 (seq_length,batch,feature)。当然如果你想和CNN一样把batch放在第一维，可将该参数设置为True。\n",
    "- dropout – 如果非0，就在除了最后一层的其它层都插入Dropout层，默认为0。\n",
    "- bidirectional – If True, becomes a bidirectional LSTM. Default: False\n",
    "\n",
    "## 输入\n",
    "input, (h_0,c_0)\n",
    "- input: 输入数据，即上面例子中的一个句子（或者一个batch的句子），其维度形状为 (seq_len, batch, input_size)\n",
    "  - seq_len: 句子长度，即单词数量，这个是需要固定的。当然假如你的一个句子中只有2个单词，但是要求输入10个单词，这个时候可以用torch.nn.utils.rnn.pack_padded_sequence()或者torch.nn.utils.rnn.pack_sequence()来对句子进行填充或者截断。\n",
    "  - batch：就是你一次传入的句子的数量\n",
    "  - input_size: 每个单词向量的长度，这个必须和你前面定义的网络结构保持一致\n",
    "- h_0：维度形状为 (num_layers * num_directions, batch, hidden_size):\n",
    "  - 结合下图应该比较好理解第一个参数的含义num_layers * num_directions， 即LSTM的层数乘以方向数量。这个方向数量是由前面介绍的bidirectional决定，如果为False,则等于1；反之等于2。\n",
    "  - batch：同上\n",
    "  - hidden_size: 隐藏层节点数\n",
    "- c_0： 维度形状为 (num_layers * num_directions, batch, hidden_size),各参数含义和h_0类似。\n",
    "\n",
    "当然，如果你没有传入(h_0, c_0)，那么这两个参数会默认设置为0。\n",
    "\n",
    "## 输出\n",
    "output, (h_n,c_n)\n",
    "- output： 维度和输入数据类似，只不过最后的feature部分会有点不同，即 (seq_len, batch, num_directions * hidden_size)这个输出tensor包含了LSTM模型最后一层每个time step的输出特征另外如果前面你对输入数据使用了torch.nn.utils.rnn.PackedSequence,那么输出也会做同样的操作编程packed sequence。对于unpacked情况，我们可以对输出做如下处理来对方向作分离output.view(seq_len, batch, num_directions, hidden_size), 其中前向和后向分别用0和1表示Similarly, the directions can be separated in the packed case.\n",
    "- h_n：(num_layers * num_directions, batch, hidden_size)，\n",
    "只会输出最后个time step的隐状态结果\n",
    "- c_n ：(num_layers * num_directions, batch, hidden_size)，只会输出最后个time step的cell状态结果（如下图所示）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8-1bOSUPmuNm"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_class, hidden_size=n_hidden, bidirectional=True) # 是否双向\n",
    "        # fc\n",
    "        self.fc = nn.Linear(n_hidden * 2, n_class) # *2因为双向 \n",
    "\n",
    "    def forward(self, X):\n",
    "        # X: [batch_size, max_len, n_class]\n",
    "        batch_size = X.shape[0]\n",
    "        input = X.transpose(0, 1)  # input : [max_len, batch_size, n_class]\n",
    "\n",
    "        hidden_state = torch.randn(1*2, batch_size, n_hidden).to(device)   # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "        cell_state = torch.randn(1*2, batch_size, n_hidden).to(device)     # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "\n",
    "        outputs, (_, _) = self.lstm(input, (hidden_state, cell_state))\n",
    "        outputs = outputs[-1]  # [batch_size, n_hidden * 2]\n",
    "        model = self.fc(outputs)  # model : [batch_size, n_class]\n",
    "        return model\n",
    "\n",
    "model = BiLSTM().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrQsawhSsXrQ"
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQDOYpw6srG9",
    "outputId": "9aa49dcd-29ec-435a-bf2a-28c6082bcac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2500 cost = 0.821938\n",
      "Epoch: 2500 cost = 0.222033\n",
      "Epoch: 2500 cost = 1.067995\n",
      "Epoch: 2500 cost = 1.481362\n",
      "Epoch: 2500 cost = 0.987236\n",
      "Epoch: 2500 cost = 0.218648\n",
      "Epoch: 2500 cost = 1.267750\n",
      "Epoch: 5000 cost = 0.742563\n",
      "Epoch: 5000 cost = 0.165926\n",
      "Epoch: 5000 cost = 0.082179\n",
      "Epoch: 5000 cost = 0.102131\n",
      "Epoch: 5000 cost = 0.344776\n",
      "Epoch: 5000 cost = 0.170287\n",
      "Epoch: 5000 cost = 0.237099\n",
      "Epoch: 7500 cost = 0.010331\n",
      "Epoch: 7500 cost = 0.248058\n",
      "Epoch: 7500 cost = 0.016673\n",
      "Epoch: 7500 cost = 0.021382\n",
      "Epoch: 7500 cost = 0.018066\n",
      "Epoch: 7500 cost = 0.255733\n",
      "Epoch: 7500 cost = 0.020288\n",
      "Epoch: 10000 cost = 0.004539\n",
      "Epoch: 10000 cost = 0.233148\n",
      "Epoch: 10000 cost = 0.001186\n",
      "Epoch: 10000 cost = 0.241349\n",
      "Epoch: 10000 cost = 0.003039\n",
      "Epoch: 10000 cost = 0.005206\n",
      "Epoch: 10000 cost = 0.001360\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(10000):\n",
    "    for x, y in loader:\n",
    "      pred = model(x.to(device))\n",
    "      loss = criterion(pred, y.to(device))\n",
    "      if (epoch + 1) % 2500 == 0:\n",
    "          print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM7FPI2ysuQ-"
   },
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXrTHIK2swsO",
    "outputId": "73fd2774-4d1c-4d80-e9d9-1ba4a8f3650a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub Actions makes it easy to automate all your software workflows from continuous integration and delivery to issue triage and more\n",
      "['Actions', 'makes', 'it', 'easy', 'to', 'automate', 'all', 'your', 'software', 'workflows', 'from', 'continuous', 'integration', 'and', 'delivery', 'to', 'issue', 'triage', 'and', 'more']\n"
     ]
    }
   ],
   "source": [
    "# Pred\n",
    "predict = model(input_batch.to(device)).data.max(1, keepdim=True)[1]\n",
    "print(sentence)\n",
    "print([idx2word[n.item()] for n in predict.squeeze()])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BiLSTM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
